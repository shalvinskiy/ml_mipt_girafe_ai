{"cells":[{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fpIKjcNAcj6t","outputId":"c9b576a4-b8b5-419d-bdb3-552371522005","executionInfo":{"status":"ok","timestamp":1672228257747,"user_tz":-180,"elapsed":11,"user":{"displayName":"Roman Shalvinskiy","userId":"07045652343945671112"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/$03DSCoding/$75code_mipt_course_ML/homeworks/lab02_deeplearn\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","\n","# !unzip -qq data.zip"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"0sk0wmS5cw3j","executionInfo":{"status":"ok","timestamp":1672228274038,"user_tz":-180,"elapsed":10,"user":{"displayName":"Roman Shalvinskiy","userId":"07045652343945671112"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"37d6f1c5-2840-4adb-a1d9-4d11b718c78e"},"outputs":[{"output_type":"stream","name":"stdout","text":[" \u001b[0m\u001b[01;34mdata\u001b[0m/\n"," \u001b[01;34mhw_var_1\u001b[0m/\n"," Lab2_DL_part1_warmup.ipynb\n"," Lab2_DL_part2_overfitting.ipynb\n"," Lab2_DL_part2_overfitting_shalvinskiy.ipynb\n"," Lab2_DL_part3_poetry.ipynb\n"," Lab2_DL_part3_poetry_shalvinskiy.ipynb\n"," Lab2_DL_part5_optional.ipynb\n"," Lab2_DL_parts_4_and_5_optional.ipynb\n"," lstm\n"," lstm_model\n"," README.md\n"," sonnets.txt\n","'UCI HAR Dataset.zip'\n"]}],"source":["%cd '/content/drive/MyDrive/$03DSCoding/$75code_mipt_course_ML/homeworks/lab02_deeplearn'\n","%ls"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"jTTyf7aResFU","executionInfo":{"status":"ok","timestamp":1672229585633,"user_tz":-180,"elapsed":2412,"user":{"displayName":"Roman Shalvinskiy","userId":"07045652343945671112"}}},"outputs":[],"source":["%ls './data/train/2'"]},{"cell_type":"code","execution_count":6,"metadata":{"collapsed":true,"id":"bec6ypy6cFtQ","executionInfo":{"status":"ok","timestamp":1672228321079,"user_tz":-180,"elapsed":6883,"user":{"displayName":"Roman Shalvinskiy","userId":"07045652343945671112"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"19a420a8-1779-4fa8-c1e0-564983c88533"},"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"]},{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," bidirectional (Bidirectiona  (1, 40)                  4800      \n"," l)                                                              \n","                                                                 \n","=================================================================\n","Total params: 4,800\n","Trainable params: 4,800\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["#check how bidirectional lstm works\n","from keras import Sequential\n","from keras.layers import Dense, Dropout, Embedding, LSTM, Bidirectional\n","model = Sequential()\n","model.add(Bidirectional(LSTM(units=20, input_dim=10, use_bias=False, input_shape=(1,10))))\n","model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n","\n","model.build((1, 10, 10))\n","model.summary()"]},{"cell_type":"markdown","metadata":{"id":"llxwsBQgcFtR"},"source":["### Part 5. Dogs classification (2+ points)\n","__Disclaimer__: Это опциональная часть задания. Здесь придется экспериментировать, подбирать оптимальную структуру сети для решения задачи и активно искать подскзаки в сети.\n","\n","Предлагаем вам решить задачу классификации пород собак. Вы можете обучить сеть с нуля или же воспользоваться методом fine-tuning'а. Полезная ссылка на [предобученные модели](https://pytorch.org/docs/stable/torchvision/models.html).\n","Ссылка изменилась, вот новая -- https://pytorch.org/vision/stable/models.html.\n","\n","Данные можно скачать [отсюда](https://www.dropbox.com/s/vgqpz2f1lolxmlv/data.zip?dl=0). Датасет представлен 50 классами пород собак, которые можно найти в папке train в соответствующих директориях. При сдаче данной части задания вместе с ноутбуком необходимо отправить .csv-файл с предсказаниями классов тестовой выборки в формате: <имя изображения>,<метка класса> по одному объекту на строку. Ниже приведите код ваших экспериментов и короткий вывод по их результатам.\n","\n","Будут оцениваться качество классификации (accuracy) на тестовой выборке (2 балла) и проведенные эксперименты (1 балл).\n","Разбалловка следующая:\n","* $>=$93% - 2 points\n","* $>=$84% - 1.5 points\n","* $>=$70% - 0.75 points"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"tOCiOJTVcFtT","executionInfo":{"status":"ok","timestamp":1672228323523,"user_tz":-180,"elapsed":2448,"user":{"displayName":"Roman Shalvinskiy","userId":"07045652343945671112"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"99de5b00-0247-42b2-b967-65eaad9c5474"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch._C.Generator at 0x7fe1203e4a10>"]},"metadata":{},"execution_count":7}],"source":["import torch\n","from torchvision import datasets, transforms, models\n","import torch.nn.functional as F\n","from torch import nn\n","from torch import optim\n","from torchvision.io import read_image\n","from torch.utils.data import DataLoader, random_split\n","\n","import torchvision.transforms as T\n","\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from tqdm import tqdm\n","from sklearn.metrics import accuracy_score\n","from torchsummary import summary\n","from IPython.display import clear_output\n","\n","import os\n","torch.manual_seed(42)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C_XhnpdBcFtU"},"outputs":[],"source":["#funciton for renaming test photos\n","def renaming():\n","    path = r'./data/test/'\n","    \n","    for file in os.listdir(path):\n","        os.makedirs(os.path.dirname(path+file.replace('.jpeg', '/')))\n","        os.rename(path + file, path + file.replace('.jpeg', '') + '/' + file)\n","renaming()"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"84OLqf7hcFtY","executionInfo":{"status":"error","timestamp":1672229422844,"user_tz":-180,"elapsed":2995,"user":{"displayName":"Roman Shalvinskiy","userId":"07045652343945671112"}},"colab":{"base_uri":"https://localhost:8080/","height":380},"outputId":"b02ca061-e88e-460c-d763-b3753f33d00e"},"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-16-8f174b877eba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m                                     \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mToTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                     transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtrainset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImageFolder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/train/'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, transform, target_transform, loader, is_valid_file)\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[0mis_valid_file\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m     ):\n\u001b[0;32m--> 309\u001b[0;31m         super().__init__(\n\u001b[0m\u001b[1;32m    310\u001b[0m             \u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, loader, extensions, transform, target_transform, is_valid_file)\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_transform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m         \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextensions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_valid_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mmake_dataset\u001b[0;34m(directory, class_to_idx, extensions, is_valid_file)\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[0;31m# is potentially overridden and thus could have a different logic.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The class_to_idx parameter cannot be None.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmake_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextensions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextensions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_valid_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_valid_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfind_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirectory\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mmake_dataset\u001b[0;34m(directory, class_to_idx, extensions, is_valid_file)\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mextensions\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34mf\"Supported extensions are: {extensions if isinstance(extensions, str) else ', '.join(extensions)}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minstances\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: Found no valid file for the classes 2, 20, 28, 35, 4. Supported extensions are: .jpg, .jpeg, .png, .ppm, .bmp, .pgm, .tif, .tiff, .webp"]}],"source":["train_transform = transforms.Compose([transforms.RandomResizedCrop(336),\n","                                    transforms.RandomHorizontalFlip(),\n","                                    transforms.ToTensor(),\n","                                    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n","trainset = datasets.ImageFolder('data/train/', transform=train_transform)\n","len(trainset)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eCPSLBWBvnFo"},"outputs":[],"source":["#ONLY FOR TESTING\n","test_transform = transforms.Compose([transforms.RandomResizedCrop(336),\n","                                    transforms.ToTensor(),\n","                                    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n","testset = datasets.ImageFolder('data/test/', transform=test_transform)\n","testloader = torch.utils.data.DataLoader(testset, batch_size=32, shuffle=True)\n","pic_to_label = testset.class_to_idx\n","label_to_pic = {pic_to_label[pic] : pic for pic in pic_to_label}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jPWmGHV1cFtZ"},"outputs":[],"source":["class_to_label = trainset.class_to_idx\n","label_to_class = {class_to_label[cl] : cl for cl in class_to_label}\n","num_classes = len(class_to_label)\n","num_classes"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uWZlIfGzMvTN"},"outputs":[],"source":["trainset_size = int(len(trainset) * 0.95)\n","validset_size = len(trainset) - trainset_size\n","trainset, validset = random_split(trainset, [trainset_size, validset_size])\n","\n","len(trainset)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rEuleYqAcFtc"},"outputs":[],"source":["trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True)\n","validloader = torch.utils.data.DataLoader(validset, batch_size=32, shuffle=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q_w-f32EcFtd"},"outputs":[],"source":["for i in trainloader:\n","    images, labels = i\n","    print(labels[0])\n","    img = images[0].numpy().transpose(1,2,0)\n","    \n","    mean = np.array([0.485, 0.456, 0.406])\n","    std = np.array([0.229, 0.224, 0.225])\n","    img = std * img + mean\n","    img = np.clip(img, 0, 1)\n","    plt.imshow(img)\n","    break"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HQ_3ri_OcFtp"},"outputs":[],"source":["def validate(model, validloader, criterion, is_cuda):\n","    val_loss = 0\n","    correct = 0\n","    total = 0\n","\n","    model.eval()\n","    for batch_idx, (data, target) in enumerate(tqdm(validloader)):\n","        if is_cuda:\n","            data, target = data.cuda(), target.cuda()\n","\n","        output = model(data)\n","        loss = criterion(output, target)\n","        \n","        val_loss = val_loss + ((1 / (batch_idx + 1)) * (loss.data - val_loss))\n","        pred = output.data.max(1, keepdim=True)[1]\n","        correct += np.sum(np.squeeze(pred.eq(target.data.view_as(pred))).cpu().numpy())\n","        total += data.size(0)\n","            \n","    print(f'\\n Validation loss: {val_loss}. Accuracy: {correct / total}({correct} out of {total})')\n","\n","    return val_loss"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"m1-HF9CKkJvR"},"outputs":[],"source":["def val_train_loop(model, testloader, validloader, optimizer, criterion, n_epochs, is_cuda, save_path):\n","    min_valid_loss = np.inf\n","    period=4\n","    loss_history = []\n","    valid_loss_history = []\n","\n","    for epoch in range(n_epochs):\n","        train_loss = 0\n","        valid_loss = 0\n","        \n","        model.train()\n","        for batch_idx, (data, target) in enumerate(tqdm(trainloader)):\n","            if is_cuda:\n","                data, target = data.cuda(), target.cuda()\n","            \n","            output = model(data)\n","            loss = criterion(output, target)\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","            \n","            train_loss = train_loss + ((1 / (batch_idx + 1)) * (loss.data - train_loss))\n","            \n","        if(epoch % period == 0):\n","          valid_loss = validate(model, validloader, criterion, is_cuda)\n","          valid_loss_history.append(valid_loss.cpu().numpy())\n","\n","          #save the model if validation loss has decreased\n","          if valid_loss < min_valid_loss:\n","              print(f'\\nValidation loss decreased ({min_valid_loss} --> {valid_loss}). Model saved')\n","              torch.save(model.state_dict(), save_path)\n","              min_valid_loss = valid_loss\n","        \n","        loss_history.append(train_loss)\n","        \n","        clear_output(wait=True)\n","        plt.figure(figsize=(8, 5))\n","        plt.title(f\"Training/validating loss\")\n","        plt.xlabel(\"#epoch\")\n","        plt.ylabel(\"Loss\")\n","        plt.plot(loss_history, 'blue', label='train')\n","        plt.scatter(np.arange(len(valid_loss_history)) * period, valid_loss_history, c ='orange', s=100, label='validate')\n","        plt.legend()\n","        plt.show()\n","\n","        print(f'\\nEpoch: {epoch}. Training loss: {train_loss}. Last valloss: {min_valid_loss}')\n","    \n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iIACgSyNkNug"},"outputs":[],"source":["vgg16 = models.vgg16(pretrained=True)\n","\n","for param in vgg16.features.parameters():\n","    param.requires_grad = False\n","    \n","if torch.cuda.is_available():\n","    vgg16 = vgg16.cuda()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YnyAdxsfOFKs"},"outputs":[],"source":["print(vgg16)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ISMmDoRux8Fp"},"outputs":[],"source":["vgg16.classifier[6].out_features = num_classes"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BuIpZy0DkRVi"},"outputs":[],"source":["criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(vgg16.classifier.parameters(), lr=0.001, momentum=0.9)\n","n_epochs = 13"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Kpa4jHUqkUTR"},"outputs":[],"source":["%%time\n","vgg16_trained = val_train_loop(vgg16, trainloader, validloader, optimizer, criterion, n_epochs, torch.cuda.is_available(), 'vgg16_no_tune.pt')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G5FBo8IrHewa"},"outputs":[],"source":["print(torch.cuda.memory_summary(device=None, abbreviated=False))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3dkyTEVRkcqi"},"outputs":[],"source":["reload_model = models.vgg16()\n","reload_model.classifier[6].out_features = num_classes  \n","reload_model.load_state_dict(torch.load('vgg16_no_tune.pt'))\n","\n","if torch.cuda.is_available():\n","    reload_model = reload_model.cuda()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2B4MmjLf5BQU"},"outputs":[],"source":["validate(reload_model, validloader, criterion, torch.cuda.is_available())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nlpLZ-_6BuIs"},"outputs":[],"source":["def test(model, testloader, is_cuda, file_name):\n","    model.eval()\n","    targets = np.array([])\n","    preds = np.array([])\n","\n","    for (data, target) in tqdm(testloader):\n","        if is_cuda:\n","            data, target = data.cuda(), target.cuda()\n","\n","        output = model(data)\n","        pred = output.data.max(1, keepdim=True)[1]\n","\n","        targets = np.concatenate((targets, target.cpu().numpy().ravel()))\n","        preds = np.concatenate((preds, pred.cpu().numpy().ravel()))\n","\n","    df = pd.DataFrame(data={'targets': np.int64(targets), 'preds': np.int64(preds)})\n","    df['targets'] = df['targets'].apply(lambda x: str(label_to_pic[x]) + '.jpeg')\n","    df['preds'] = df['preds'].apply(lambda x: label_to_class[x])\n","    df['nums'] = df['targets'].apply(lambda x: int(x.replace('.jpeg', '')))\n","    df.sort_values('nums').to_csv(file_name)\n","    return df\n","\n","df = test(reload_model, testloader, torch.cuda.is_available(), 'vgg16_no_tune_resuls.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hGvUEgMn_E_6"},"outputs":[],"source":["df.sort_values('nums').head(6)"]},{"cell_type":"markdown","metadata":{"id":"AKjCDcN1CZhr"},"source":["### New train "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x7hM51vSCjwc"},"outputs":[],"source":["vgg16 = models.vgg16(pretrained=True)\n","\n","for param in vgg16.features.parameters():\n","    param.requires_grad = False\n","    \n","if torch.cuda.is_available():\n","    vgg16 = vgg16.cuda()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4VqUGdGnCj33"},"outputs":[],"source":["vgg16.classifier[6].out_features = num_classes"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-xMjf50HCj6e"},"outputs":[],"source":["criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(vgg16.classifier.parameters(), lr=0.001, momentum=0.9)\n","n_epochs = 9"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Dom1Tg5HCj9B"},"outputs":[],"source":["%%time\n","vgg16_trained = val_train_loop(vgg16, trainloader, validloader, optimizer, criterion, n_epochs, torch.cuda.is_available(), 'vgg16_no_tune_2.pt')"]},{"cell_type":"markdown","metadata":{"id":"5x1pRQtqWcdP"},"source":["Продолжим тренировку модели"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SQ6w2Nu5WkI3"},"outputs":[],"source":["criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(vgg16.classifier.parameters(), lr=0.001, momentum=0.7)\n","n_epochs = 5"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fIss1R5OWSeI"},"outputs":[],"source":["%%time\n","vgg16_trained = val_train_loop(vgg16_trained, trainloader, validloader, optimizer, criterion, n_epochs, torch.cuda.is_available(), 'vgg16_no_tune_2.pt')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BGl6n2IJgFvG"},"outputs":[],"source":["df = test(vgg16_trained, testloader, torch.cuda.is_available(), 'vgg16_no_tune_2_results.csv')\n","df.sort_values('nums').head(6)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tURu5vhgkXwM"},"outputs":[],"source":["criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(vgg16.classifier.parameters(), lr=0.0001, momentum=0.7)\n","n_epochs = 1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zfH5bE-ZkcM2"},"outputs":[],"source":["%%time\n","vgg16_trained = val_train_loop(vgg16_trained, trainloader, validloader, optimizer, criterion, n_epochs, torch.cuda.is_available(), 'vgg16_no_tune_2.pt')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iggep6k_o_kC"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"Paz7N4qGg9ON"},"source":["**Вывод** Пока что это лучший результат, также была предпринята попфтка дообучения модели птуем угулюления головы(добавил несколько linear, relu, dropout слоев, получилось хуже, обучение шло еще медленнее, loss был огромным. Также за эту работу сравнил adam и sgd отпимизаторы, осознал, насколько важно правильно подбирать параметры lr, momentum, в итоге получилось достичь точности в 82% на валидационной выборке"]},{"cell_type":"markdown","metadata":{"id":"SlN7EwpQW3om"},"source":["Еще одна попытка, будем дообучать resnet"]},{"cell_type":"markdown","metadata":{"id":"Z-kMmlcGcddb"},"source":["(0): Linear(in_features=25088, out_features=4096, bias=True)\n","\n","(1): ReLU(inplace=True)\n","\n","(2): Dropout(p=0.5, inplace=False)\n","\n","(3): Linear(in_features=4096, out_features=4096, bias=True)\n","\n","(4): ReLU(inplace=True)\n","\n","(5): Dropout(p=0.5, inplace=False)\n","\n","(6): Linear(in_features=4096, out_features=1000, bias=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"icmAvqbADLtE"},"outputs":[],"source":["resnet18 = models.resnet18(pretrained=True)\n","resnet18"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dSPAyzvBXJ6v"},"outputs":[],"source":["for param in resnet18.parameters():\n","    param.requires_grad = False\n","  \n","classifier = nn.Sequential(nn.Linear(512, 1024), \n","                           nn.ReLU(),\n","                           nn.Dropout(p=0.5),\n","                           nn.Linear(1024, 2048), \n","                           nn.ReLU(),\n","                           nn.Dropout(p=0.5), \n","                           nn.Linear(2048, num_classes)\n","                           )\n","\n","resnet18.fc = classifier"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x69aMUhCd5Vj"},"outputs":[],"source":["criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(resnet18.fc.parameters(), lr=0.001, momentum=0.7)\n","n_epochs = 5"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LTZXlGQcf7PA"},"outputs":[],"source":["%%time\n","resnet18_trained = val_train_loop(resnet18, trainloader, validloader, optimizer, criterion, n_epochs, torch.cuda.is_available(), 'resnet18.pt')"]}],"metadata":{"accelerator":"GPU","anaconda-cloud":{},"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":0}